{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement the SGD, momentum, Adagrad, RMSProp and Adam methods.\n",
    "\n",
    "un the code, you can see the animation display online in this notebook. I also saved the animations as a gifs for easy viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker, cm\n",
    "import seaborn as sns\n",
    "from ipywidgets import *\n",
    "import math\n",
    "import matplotlib.animation\n",
    "\n",
    "sns.set_context('paper', font_scale=2)\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_2d(x1, x2):\n",
    "    '''original function to minimize'''\n",
    "    return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "def f_grad(x1, x2):\n",
    "    '''the gradient dfdx1 and dfdx2'''\n",
    "    dfdx1 = 0.2 * x1\n",
    "    dfdx2 = 4 * x2\n",
    "    return dfdx1, dfdx2\n",
    "\n",
    "def train_2d(trainer, lr):\n",
    "    \"\"\"Train a 2d object function with a customized trainer\"\"\"\n",
    "    x1, x2 = -5, -2\n",
    "    s_x1, s_x2 = 0, 0\n",
    "    res = [(x1, x2)]\n",
    "    for i in range(50):\n",
    "        x1, x2, s_x1, s_x2, lr = trainer(x1, x2, s_x1, s_x2, lr)\n",
    "        res.append((x1, x2))\n",
    "    return res\n",
    "\n",
    "def plot_2d(res, figsize=(10, 6), title=None):\n",
    "    x1_, x2_ = zip(*res)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.plot([0], [0], 'r*', ms=15)\n",
    "    plt.text(0.0, 0.25, 'minimum', color='w')\n",
    "    plt.plot(x1_[0], x2_[0], 'ro', ms=10)\n",
    "    plt.text(x1_[0]+0.1, x2_[0]+0.2, 'start', color='w')\n",
    "    plt.plot(x1_, x2_, '-o')\n",
    "    \n",
    "    plt.plot(x1_[-1], x2_[-1], 'wo')\n",
    "    plt.text(x1_[-1], x2_[-1]-0.25, 'end', color='w')\n",
    "    \n",
    "    x1 = np.linspace(-5.5, 3, 50)\n",
    "    x2 = np.linspace(min(-3.0, min(x2_) - 1), max(3.0, max(x2_) + 1), 100)\n",
    "    x1, x2 = np.meshgrid(x1, x2)\n",
    "    plt.contourf(x1, x2, f_2d(x1, x2), cmap=cm.viridis)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD\n",
    "\n",
    "\n",
    "\n",
    "$$\\theta = \\theta - \\eta \\cdot \\nabla_{\\theta} L(\\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3818f13a3ec41a59f8bd2f80fd8fc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.05, description='lr', max=1.0, step=0.001), Output()), _dom_classes=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sgd(x1, x2, s1, s2, lr):\n",
    "    dfdx1, dfdx2 = f_grad(x1, x2)\n",
    "    return (x1 - lr * dfdx1, x2 - lr * dfdx2, 0, 0, lr)\n",
    "\n",
    "@interact(lr=(0, 1, 0.001))\n",
    "def visualize_gradient_descent(lr=0.05):\n",
    "    res = train_2d(sgd, lr)\n",
    "    plot_2d(res, title='SGD')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum\n",
    "$$v_t = \\gamma v_{t-1} + \\eta \\cdot \\nabla_{\\theta} L(\\theta)$$\n",
    "$$\\theta = \\theta - v_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633ed1b53e714110908d632fa6f2861d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lr', max=0.99, step=0.001), FloatSlider(value=0.1, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(lr=(0, 0.99, 0.001), gamma=(0, 0.99, 0.001),\n",
    "         continuous_update=False)\n",
    "def visualize_sgd_momentum(lr=0.1, gamma=0.1):\n",
    "    '''lr: learning rate\n",
    "    gamma: parameter for momentum sgd'''\n",
    "    \n",
    "    def momentum(x1, x2, v1, v2, lr):\n",
    "        dfdx1, dfdx2 = f_grad(x1, x2)\n",
    "        v1 = gamma * v1 + lr * dfdx1\n",
    "        v2 = gamma * v2 + lr * dfdx2\n",
    "        x1 = x1 - v1\n",
    "        x2 = x2 - v2\n",
    "        return (x1, x2, v1, v2, lr)\n",
    "    \n",
    "    res = train_2d(momentum, lr)\n",
    "    plot_2d(res, title='momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Adagrad\n",
    " $$ g_t =  \\nabla_{\\theta} L(\\theta)$$\n",
    "\n",
    "$$ G = \\sum_{t} g_t^2$$\n",
    "\n",
    "$$\\theta = \\theta - \\frac{\\eta}{\\sqrt{G + \\epsilon}} \\cdot g_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7cafb87fe9498c86a695ba18bfe60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lr', max=4.0, step=0.01), Output()), _dom_classes=('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(lr=(0, 4, 0.01),\n",
    "          continuous_update=False)\n",
    "def visualize_adagrad(lr=0.1):\n",
    "    '''lr: learning rate'''\n",
    "    def adagrad_2d(x1, x2, s1, s2, lr):\n",
    "        g1, g2 = f_grad(x1, x2)\n",
    "        eps = 1e-6\n",
    "        s1 += g1 ** 2\n",
    "        s2 += g2 ** 2\n",
    "        x1 -= lr / math.sqrt(s1 + eps) * g1\n",
    "        x2 -= lr / math.sqrt(s2 + eps) * g2\n",
    "        return x1, x2, s1, s2, lr\n",
    "    \n",
    "    res = train_2d(adagrad_2d, lr)\n",
    "    plot_2d(res, title='adagrad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp \n",
    "\n",
    "$$ g = \\nabla_{\\theta} L(\\theta) $$\n",
    "\n",
    "$$ E\\left[g^2\\right] = \\gamma E\\left[g^2\\right] + (1-\\gamma) g^2 $$\n",
    "\n",
    "$$\\theta = \\theta - \\frac{\\eta}{\\sqrt{E\\left[g^2\\right] + \\epsilon}} \\cdot g$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2365cd22153449bab46e2fa4772ed017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lr', max=1.0, step=0.001), FloatSlider(value=0.9, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(lr=(0, 1, 0.001), \n",
    "          gamma=(0, 0.99, 0.001),\n",
    "          continuous_update=False)\n",
    "def visualize_rmsprop(lr=0.1, gamma=0.9):\n",
    "    '''lr: learning rate, \n",
    "       gamma: momentum'''  \n",
    "    def rmsprop_2d(x1, x2, s1, s2, lr):\n",
    "        eps = 1e-6\n",
    "        g1, g2 = f_grad(x1, x2)\n",
    "        s1 = gamma * s1 + (1 - gamma) * g1 ** 2\n",
    "        s2 = gamma * s2 + (1 - gamma) * g2 ** 2\n",
    "        x1 -= lr / math.sqrt(s1 + eps) * g1\n",
    "        x2 -= lr / math.sqrt(s2 + eps) * g2\n",
    "        return x1, x2, s1, s2, lr\n",
    "\n",
    "    res = train_2d(rmsprop_2d, lr)\n",
    "    plot_2d(res, title='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam\n",
    "\n",
    "$$ g = \\nabla_{\\theta} L(\\theta) $$\n",
    "\n",
    "$$ m = \\beta_1 m + (1 - \\beta_1) g $$\n",
    "\n",
    "$$ n = \\beta_2 n + (1 - \\beta_2) g^2 $$\n",
    "\n",
    "$$ \\hat{m} = \\frac{m}{(1 - \\beta_1^t)} $$\n",
    "\n",
    "$$ \\hat{n} = \\frac{n}{(1 - \\beta_2^t)} $$\n",
    "\n",
    "$$\\theta = \\theta - \\frac{\\eta}{\\sqrt{\\hat{n}} + \\epsilon} \\hat{m}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c21d0517464a3f811961471880e184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='lr', max=1.0, step=0.001), FloatSlider(value=0.9, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(lr=(0, 1, 0.001), \n",
    "          beta1=(0, 0.999, 0.001),\n",
    "          beta2=(0, 0.999, 0.001),\n",
    "          continuous_update=False)\n",
    "def visualize_adam(lr=0.1, beta1=0.9, beta2=0.999):\n",
    "    '''lr: learning rate\n",
    "    beta1: parameter for E(g)\n",
    "    beta2: parameter for E(g^2)\n",
    "    '''  \n",
    "    def Deltax(m, n, g, t):\n",
    "        eps = 1.0E-6\n",
    "        m = beta1 * m + (1 - beta1) * g\n",
    "        n = beta2 * n + (1 - beta2) * g*g\n",
    "        m_hat = m / (1 - beta1**t)\n",
    "        n_hat = n / (1 - beta2**t)\n",
    "        dx = lr * m_hat / (math.sqrt(n_hat) + eps)\n",
    "        return m, n, dx\n",
    "        \n",
    "    def adam_2d(x1, x2, m1, n1, m2, n2, lr, t):\n",
    "        '''m1, m2: E(g1), E(g2)\n",
    "           n1, n2: E(g1^2), E(g2^2) where E() is expectation\n",
    "           lr: learning rate\n",
    "           t: time step'''\n",
    "        eps = 1e-6\n",
    "        g1, g2 = f_grad(x1, x2)\n",
    "        m1, n1, dx1 = Deltax(m1, n1, g1, t)\n",
    "        m2, n2, dx2 = Deltax(m2, n2, g2, t)       \n",
    "        x1 -= dx1\n",
    "        x2 -= dx2\n",
    "        return x1, x2, m1, n1, m2, n2, lr\n",
    "    \n",
    "    def train_adam(trainer, lr):\n",
    "        \"\"\"Train a 2d object function with a customized trainer\"\"\"\n",
    "        x1, x2 = -5, -2\n",
    "        m1, n1, m2, n2 = 0, 0, 0, 0\n",
    "        res = [(x1, x2)]\n",
    "        for i in range(30):\n",
    "            x1, x2, m1, n1, m2, n2, lr = trainer(x1, x2, m1, n1, m2, n2, lr, i+1)\n",
    "            res.append((x1, x2))\n",
    "        return res\n",
    "    \n",
    "    res = train_adam(adam_2d, lr)\n",
    "    plot_2d(res, title='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
